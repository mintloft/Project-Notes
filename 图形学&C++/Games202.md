# Games202

## 3D基础

**Opengl 做了什么**：

<img src="F:\计算机图形学\games202\1.png" style="zoom: 50%;" />

**VBO**: Opengl将模型的 顶点，纹理坐标，法线存储在VBO这片GPU的区域中。

**gluPerspective**：在opengl中调用view矩阵，只需要定义好gluPerspective函数中相机属性参数就可以（宽高比，可视角度，近远平面）

<img src="F:\计算机图形学\games202\2.png" style="zoom:50%;" />

在opengl中一个画架可以画出多张图，其实就是一个framebuffer光栅化一次可以输出渲染出不同的纹理

**垂直同步**：如果将framebuffer中的结果渲染到屏幕上，由于framebuffer输出不同的纹理，如果上一帧渲染的纹理，下一帧再进行渲染，会造成画面撕裂，那么垂直同步可以解决这个问题

**双缓冲：**将渲染的结果缓存到纹理，或者一个缓冲区里面去，等渲染结束后，在屏幕上在进行显示

**渲染步骤总结：**

1.定义要渲染的物体，场景信息

2.定义MVP变换矩阵，摄像机信息

3.定义gpu选择的framebuffer（画架），定义好framebuffer输出的纹理，纹理个数

4.告诉gpu顶点或片段渲染的着色器

5.最后拿去渲染

**为什么场景要渲染多次：**参考101中shadowmap，首先第一次测光源到场景的深度渲染，再去测camera到场景的深度渲染。

**渲染前 **对于opengl要进行shader的程序编译，再将顶点着色与片段着色程序放在一个program中，在program中对于顶点着色与片段着色进行一个链接检查

<img src="F:\计算机图形学\games202\3.png" style="zoom: 50%;" />

对于点与fragment的着色都是对于在for循环内的shader

<img src="F:\计算机图形学\games202\4.png" style="zoom:50%;" />

**环境光照：**

<img src="F:\计算机图形学\games202\5.png" style="zoom: 67%;" />

**cubmap，sphere map** 

从shading point的一点上向环境的wi方向去，决定visibility是否可见



## 实时阴影渲染

![](F:\计算机图形学\games202\v2-b557339f72424bc56c0be508965b7f40_720w.jpg)



#### **shadowmapping**：（渲染两次）

1.从光源看向场景，渲染一遍场景后，输出一个场景中最浅的深度。

2.有了第一次path输出的Texture可以交给framebuffer（规定交给的是一个深度），第二次的path从相机出发渲染整个场景检测现在相机所看到的任何一个点是否在阴影中。

**优点：**得到shadowmap后不需要场景中的几何表示

**缺点：**  会发生走样，锯齿。  会发生自遮挡现象

<img src="F:\计算机图形学\games202\7.png" style="zoom: 50%;" />

<img src="F:\计算机图形学\games202\8.png" style="zoom:50%;" />

<img src="F:\计算机图形学\games202\9.png" style="zoom: 50%;" />

#### **RTR中的近似（实则是积分不等式）**

<img src="F:\计算机图形学\games202\10.png" style="zoom:50%;" />

<img src="F:\计算机图形学\games202\11.png" style="zoom:50%;" />

#### PCSS：（产生软阴影的方法）

<img src="F:\计算机图形学\games202\12.png" style="zoom: 33%;" />

**软阴影为什么有渐变的效果：**在本影与半影的区域，看向光源，部分角度能看到光源，部分看不到光源

**PCF解决了软阴影的问题**

<img src="F:\计算机图形学\games202\13.png" style="zoom:33%;" />

**PCF ** 的filter并不是对shadingmap做的模糊，也不是对最后生成的效果图的模糊，而是从shadingpoint这一点的深度与周围的九个像素的深度进行比较，生成一个01矩阵，再对这个矩阵进行一个平均.

【其实做的效果就可联想成：在本影与半影的区域，看向光源，部分角度能看到光源，部分看不到光源】

**PCSS**

制作软阴影效果：对于硬阴影各处不同的位置上应有一个不同大小的filter，filter的size取决于遮挡物和阴影接受物的距离有关。

<img src="F:\计算机图形学\games202\14.png" style="zoom: 33%;" />

PCF是用来做抗锯齿（反走样），但是后来人们发现这个技术还可以做软阴影，于是有了PCSS.

**PCSS的具体步骤如下：**

- 首先依据着色点选择一块范围，对Shadow Map做一次局部深度测试判断这个点在不在阴影里，在阴影里就是blocker，找到范围内的blocker并计算其平均深度（计算平均深度的目的是减小遮挡物自身的几何影响，避免漏光）

- 得到 ![[公式]](https://www.zhihu.com/equation?tex=d_%7Bblocker%7D) 后代入公式计算滤波范围， ![[公式]](https://www.zhihu.com/equation?tex=d_%7Bblocker%7D) 越小， ![[公式]](https://www.zhihu.com/equation?tex=d_%7Breceiver%7D-d_%7Bblocker%7D) 越大，卷积核越大，得到的阴影就越软
- 重新进行深度测试，继续完成PCF的过程

这里有个问题，filter size可以按上述方法确定了，那么计算filter size时需要用到的 ![[公式]](https://www.zhihu.com/equation?tex=d_%7Bblocker%7D) 同样需要在一定范围内做平均，这个范围又怎么确定呢？我们可以认为规定一个固定的大小，如4乘4，16乘16等，但这么做绝对不是最优解，更好的方法是在光源处设置一个视锥，将shadow map置于近平面上，接着连接着色点和光源，以其在shadow map上所截得的范围作为样本，来计算平均深度

这么做有一个非常大的好处，就是计算 ![[公式]](https://www.zhihu.com/equation?tex=d_%7Bblocker%7D) 也采用了自适应的方法，离光源越远，遮挡物越多，计算blocker所用的样本范围就越小；而离光源越近，遮挡物越少，计算blocker所用的样本空间就越大，非常合理

<img src="F:\计算机图形学\games202\6.png" style="zoom:50%;" />

| Q：多光源怎么处理？                                     |
| ------------------------------------------------------- |
| A：如果是Shadow Mapping的话，只能一个个算               |
| Q：点光源和方向光源怎么做PCSS？                         |
| A：前提错了，点光源和方向光源只能产生硬阴影，用不着PCSS |
| Q：运动物体怎么办？                                     |
| A：这和运动物体没关系，因为每一帧的Shadow Map都会重新算 |

**深入理解PCF**

通过这个公式我们也能更清楚的理解，为什么PCF的滤波对象不是shadow map和阴影图，而是一定filter size内的0-1样本了.

其中权重 ![[公式]](https://www.zhihu.com/equation?tex=w%28p%2Cq%29) 可以由p和q之间的距离来定义，而乘号后的符号函数 ![[公式]](https://www.zhihu.com/equation?tex=%5Cchi%5E%2B%5BD_%7B%7D%28q%29-D%28x%29%5D) 就是深度测试的过程

<img src="F:\计算机图形学\games202\15.png" style="zoom: 50%;" />

**那么再看回PCSS的三个步骤：**

<img src="F:\计算机图形学\games202\16.png" style="zoom: 33%;" />

很容易发现在步骤一和步骤三中都存在着遍历采样shadow map进行深度比较的操作，这对实时渲染来说是非常慢的。当然了，我们可以选择不遍历，而是通过随机采样的方式得到一个近似的结果，但这样也就意味着会引入一些噪声。

工业界通常的处理方式就是这样，先对shadow map稀疏采样，再在图像空间内对含噪声结果进行一步降噪，就可以获得比较好的结果。至于怎么降噪，到之后的实时光线追踪部分再说。

#### VSSM

**与PCF作类比：** 

类比一个场景，在某次考试后，你想知道自己在班中的排名百分比，所以说PCF的过程是在用你的分数与其余同学的分数一一比较，从而获取精确的排位。

那么VSSM就更像是在基于历史经验，省去遍历比较的过程而直接估计出排位。

这种方法，在shadowmap中的depth实则可近似**假设**看成是一种**正态分布**，对于正态分布，我们一般只关注其  **均值** 与 **方差**

<img src="F:\计算机图形学\games202\17.png" style="zoom:33%;" />

**求解均值：**

对于快速求样本的**均值：**

**MipMap**：或许是一个不错的方法，在101中提到过，它是一个**快速的、近似的、正方形查询**方法，只不过在101中，这个算法是为了解决纹理过大的问题.

<img src="F:\计算机图形学\games202\18.png" style="zoom: 50%;" />

**SAT：**可以对任意的2D的矩形结构求均值

这个方法虽然简单，但一方面它要做三次插值，准确度不太高，另一方面，它只能做正方形查询，局限性太大（各向异性过滤可以解决），所以有人就提出了另一种方法——采用前缀和数组表（SAT）这一数据结构进行加速。

SAT其实相当于一种预处理操作，在一维的情况下，SAT数组中的每一项SAT[i]都保存input数组前 i 项之和，假如想要知道图中原数组第3项到第6项元素之和，就只需要拿SAT数组中的第6项减去第3项就行了

![img](https://pic4.zhimg.com/80/v2-32bb45fc4161ab1a85e3e5f4c1d183c3_720w.jpg)

对于二维的情况，生成SAT可以先并行的建立每一行的SAT，再在此基础上对列并行累加，不难算出，建立这样一张表需要的时间复杂度为 ![[公式]](https://www.zhihu.com/equation?tex=O%28m%2An%29) ，虽然建立的过程是并行的，但现代gpu往往具有更高的并行度，这样一个算法仍会显得比较“慢”

至于二维的查询就很简单了，想要获得任一矩形内元素的总和，只需要查4次表，用图中两个绿色矩形对应的SAT元素之和减去两个橙色矩形之和就行，这是最简单的容斥原理，也是leetcode 1314 matrix block sum这道经典算法题的基本思路

![img](https://pic3.zhimg.com/80/v2-cbd613b9a8fadd03c88aa12d65e30572_720w.jpg)

得到矩形区域内的元素和，再求样本均值就不在话下了。现在我们有了这一快速求均值的方法，再来看怎么求样本的方差

有了均值与方差就可以绘制出正态分布函数，对于一个x轴上确定数值，就可以求出这一点的CDF

<img src="F:\计算机图形学\games202\19.png" style="zoom:33%;" />

**切比雪夫近似**

我们知道，实时渲染中常常会把一些不等式当做约等式来使用，VSSM就利用了这一点，通过切比雪夫不等式，用求得的期望和方差近似的估计CDF的值。这同时也是VSSM的第二个大胆假设

![img](https://pic1.zhimg.com/80/v2-04c05e25bf74f2671382036266dec0f0_720w.jpg)

这个约等式可以快速的求出下图中红色部分的概率，也就是 ![[公式]](https://www.zhihu.com/equation?tex=1-CDF%28t%29) ，**并且不仅仅是正态分布，它还适用于其他任何的单峰函数**，这也是为什么VSSM不需要假设样本服从正态分布的原因

**切比雪夫近似也有它自己的局限性**

那就是t必须位于均值右侧，即 ![[公式]](https://www.zhihu.com/equation?tex=t%3EE%28x%29) 时约等关系才成立（对正态分布这个其实很好解决，把t转化为 ![[公式]](https://www.zhihu.com/equation?tex=2%5Cmu+-t) 就行了)

![img](https://pic2.zhimg.com/80/v2-92ca5713f3781a191214a9263419ada9_720w.jpg)

<img src="F:\计算机图形学\games202\20.png" style="zoom:50%;" />

#### Blocker Search加速

**在计算PCSS第一步时，进行blocker search时也同样可运用处理第三步shadingmap的切比雪夫近似方法**

<img src="F:\计算机图形学\games202\21.png" style="zoom: 67%;" />

如前文所述，我们在第一步的主要目标是计算遮挡物的平均深度，按PCSS的做法是要先对shadow map采样，判断哪些是遮挡物

![img](https://pic1.zhimg.com/80/v2-1b2b62a44cdd1c99357959956f2aef64_720w.jpg)

VSSM却直接忽略了这一步，以上图5*5的范围为例，它将深度小于着色点的蓝色遮挡区域的平均深度记作 ![[公式]](https://www.zhihu.com/equation?tex=Z_%7Booc%7D) ，而深度大于着色点的红色非遮挡区域的平均深度记作 ![[公式]](https://www.zhihu.com/equation?tex=Z_%7Bunooc%7D) ，则易得

![img](https://pic3.zhimg.com/80/v2-2de9347e59acf5e9e193c8be27373b5a_720w.jpg)

其中 ![[公式]](https://www.zhihu.com/equation?tex=%5Cfrac%7BN1%7DN) 和 ![[公式]](https://www.zhihu.com/equation?tex=%5Cfrac%7BN2%7DN) 分别表示遮挡物和非遮挡物的占比，刚好可以用**第三步（切比雪夫近似)**完全一样的方法快速求得

![img](https://pic1.zhimg.com/80/v2-219b6bb77f45f38982e609d1a170abb8_720w.jpg)

剩下还有 ![[公式]](https://www.zhihu.com/equation?tex=Z_%7Booc%7D) 和 ![[公式]](https://www.zhihu.com/equation?tex=Z_%7Bunooc%7D) 未知，在这里VSSM再一次做出大胆的假设，直接认为 ![[公式]](https://www.zhihu.com/equation?tex=Z_%7Bunooc%7D%3DZ_%7Bshading%5C+point%7D) ，认为， ![[公式]](https://www.zhihu.com/equation?tex=Z_%7Booc%7D) 随之迎刃而解

![img](https://pic2.zhimg.com/80/v2-807f06391941e881af1c8cb0b744a159_720w.jpg)

如此假设不无它的道理，因为大多数情况下阴影的接受物都接近一个平面，但这也就意味着只要接受平面是曲面，或者遇到光线掠射的情况，VSSM就会出现一些问题.VSSM的缺陷

**VSSM的缺陷主要表现在如下几点：**

- 漏光（Light Leakiing）：VSSM将遮挡物分布强行假设为单峰分布，但有时候会与实际情况相差很远，如下左图，如果实际的非遮挡区域占比比假设小，那么就会得到一个局部较亮的结果，导致漏光

  <img src="F:\计算机图形学\games202\22.png" style="zoom: 50%;" />

  <img src="F:\计算机图形学\games202\23.png" style="zoom: 50%;" />

- 不连续阴影：在算 ![[公式]](https://www.zhihu.com/equation?tex=d_%7Bblocker%7D) 的时候，VSSM假设非遮挡平面深度都等于shading point深度，这会导致在阴影接受面不平整的时候出现阴影中断现象

![img](https://pic2.zhimg.com/80/v2-5c1bde431a04a012131b1c66de2a4b29_720w.jpg)

- 使用切比雪夫近似本身具有一定局限，就是在计算的depth的值一定要超过平均值才是准的，否则不准

#### MSM

就像VSSM的提出是为了改进PCSS，MSM（Moment Shadow Mapping）的存在是为了解决VSSM假设带来的一些缺陷

其核心思想是，使用更高阶的矩来描述遮挡概率的CDF，使其更接近真实分布，从而避免漏光

关于矩的概念，它是数学中对变量的一种特征度量值，最简单的就是一个数的几次方，统计学中的期望是一阶矩，方差是二阶矩，所以从这个角度理解，VSSM就相当于记录了前两阶的矩

![img](https://pic2.zhimg.com/80/v2-53a1f38d1a82e42577a6bf57b57b1509_720w.jpg)

使用更高阶的矩就能得到更好的拟合，但是如何用更高阶的矩描述CDF是一件非常复杂的事情，同样需要相当的额外空间开销和性能开销

## 距离场阴影（DFSS）

### 有向距离场（SDF）

又称有符号距离场，是一种**标量场**，场中每一点都记录了该点到定义该场的物体之间的最小距离，并且用正负号表示该点在物体内还是在物体外，若距离为0，则认为该点在物体表面上

课程一共提到了三种SDF的应用：字体渲染，几何形变和光线步进（Ray Marching）

字体渲染方面，因为距离场记录的是标量信息，不会受到分辨率限制，并且在细微层面可以通过插值进行拟合，所以有时候能做出很好的抗锯齿效果，甚至能实现无限分辨率的字符（已在商用引擎中得到应用，但对中文支持欠佳）

（距离场等值线类似于地理上的等高线）

![img](https://pic1.zhimg.com/80/v2-4cc94411de29078db4b04bed963a1f38_720w.jpg)

而在几何方面，我们在101中讲距离函数的时候就提到过了，不同的物体有不同的距离场，在距离场与距离场间做插值运算，就能很好的进行混合过渡

![img](https://pic4.zhimg.com/80/v2-a00e608041c4061d112c45607062e427_720w.jpg)

![img](https://pic1.zhimg.com/80/v2-1d731721f7fd29933acd632041aaa934_720w.jpg)

### Ray Marching & DFSS

我们的重心主要放在Ray Marching上。采用了SDF的光线步进算法提供了一种截然不同的与场景物体求交的方法，具体来说，当我们向场景中投射一根光线的时候，Ray Marching会依据场景中每个物体的SDF，在投射点位置选取一个最小距离作为安全距离当做步长，也就是说在以投射点为球心、安全距离为半径的球形范围内，不论光线方向为何，它都不会与场景内物体相交，而当光线按原来方向走过这一段步长后，它又可以在新的位置依据SDF计算出新的安全距离，以此类推，直到步进次数达到一定值或者步长小到一定范围，即可认为光线与物体相交，退出循环

![img](https://pic3.zhimg.com/80/v2-2544570919baf7571c763afcc8390b42_720w.jpg)

**DFSS**

现在可以对这个方法稍微做一个延伸，既然我们可以通过距离场算出安全距离，那么算出一根光线在当前位置的“安全角度”应该也是非常简单的，只需要用**安全距离**与**累加的步长**和做一步**反三角**运算就可以得到了。

**计算安全角度西特**

<img src="F:\计算机图形学\games202\24.png" style="zoom:50%;" />

此时，我们连接面光源的中心与着色点，在这个方向上做Ray Marching，得到一系列安全角度后取个**最小值**作为**最终的安全角度**，这个**角度越小**，就说明**光线被遮挡的概率越高**，阴影就可以设置的越黑，反过来，当这个角度大于一定值时，就可以认为光线不被遮挡，不产生阴影

不过，上面说的用反三角算安全角还是有点废性能，于是iq大佬就提出了一种实时渲染的近似方法：

![img](https://pic1.zhimg.com/80/v2-208e66d207e832eee0d5af08999c25dc_720w.jpg)

直接用一个k与sin值相乘，再截断在1以内直接作为Visibility的值（绝了wc），虽然说这么做近似非常胆大，但通过这种方式我们获得了一个非常好的控制参数——k

同等安全角度下，k越小，visibility越小，半影区越大，阴影越软；k越大，visibility越容易被1截断，阴影越硬

### 性能分析

DFSS是一种非常聪明 效果也非常好的阴影算法，但如果说DFSS比Shadow Map系列算法快的话其实是非常不公平的，因为DFSS本质上是一种预计算，而我们一般说的DFSS速度快，是忽略了它本身计算储存SDF的时间的，要知道，三维下的SDF在空间上的消耗可不是一般的大，尤其是对于场景内有物体发生形变的情况，还得重新计算SDF，从这点上来看，算上预处理的性能消耗，DFSS和SDF目前差距并不大，我们学习他只是为了参考它巧妙的处理方法而已。

我们可以用类似kdtree树的数据结构存储空间中的区域，在树的每个叶子结点上也就是图形的边缘部分存储边缘部分的SDF。

| Q：查询空间中某个点的距离场时需要遍历场景中所有物体吗        |
| ------------------------------------------------------------ |
| A：不需要，预处理的时候每个物体单独算距离场，查询的时候只要取所有距离场在该位置的最小值即可 |
| Q：使用SDF会有什么问题吗？                                   |
| A：SDF生成的物体表面不太好贴纹理，如何参数化（UV）现在正在研究中 |
| Q：SDF得到的阴影是真的阴影吗？                               |
| A：不是，只会更假                                            |

## 环境贴图

环境贴图是一种记录了场景中任意一点在不同方向上接受到的光照强度的贴图（天空盒 / 天空球），它默认这些环境光来自**无穷远**，因此它所记录的**强度与位置无关**，（假设场景中有两个不同的物体，两个不同的物体位置不一样，但是接收到的环境光照却是完全相同的）（这也是为什么用环境贴图渲染的时候，走到哪里都会有一种漂浮感）

目前主流的环境贴图包括Spherical Map和Cube Map。类似这种处理环境光照的方法被统称为IBL（image-based lighting）

<img src="https://pic2.zhimg.com/80/v2-5aee40ea90dd74677061cec3d65f932d_720w.jpg" alt="img" style="zoom: 67%;" />

### Split-Sum近似

首先来看渲染方程

![img](https://pic2.zhimg.com/80/v2-d533938e91ec6a0447165c5eb5001a29_720w.jpg)

这里我们假设不考虑遮挡，所以直接舍去Visibility。按照之前路径追踪的做法，我们要解这个渲染方程需要借助蒙特卡洛积分去进行一个（无偏的）估计，但做过101作业7的应该都知道，蒙特卡洛需要非常大的采样率才能让结果接近真实，这对于实时的环境光照来讲是一件极其恐怖的事情，相当于对场景中每个图元都要做这么多次采样，无疑是非常慢的

（p.s.由于近几年TAA等一系列temporal方法的发展，使得一些采样方法已经能在实时领域得到应用，所以sampling对实时来说非常慢这个观点正在逐渐成为历史，但在那之前我们还是优先考虑其他不采样的方法）

这时候我们就又要用到那个在实时渲染中非常重要的积分近似公式了

![img](https://pic3.zhimg.com/80/v2-84981de15e4f2d97e1103bba75cb8c2e_720w.jpg)

<img src="F:\计算机图形学\games202\25.png" style="zoom: 50%;" />

之前提这个公式的时候说，**当 ![[公式]](https://www.zhihu.com/equation?tex=g%28x%29) 的积分域很小**，或**当 ![[公式]](https://www.zhihu.com/equation?tex=g%28x%29) 在其积分域内足够光滑（低频)**的时候，这个约等式的近似结果会更加准确，而渲染方程中的brdf项又无非分为glossy和diffuse两种，glossy对应积分域小，diffuse对应低频，那我们理所应当的就可以把light项给拆出来了

![img](https://pic3.zhimg.com/80/v2-484ac15d0ea94d3ddd7ea4fadd14389e_720w.jpg)

![img](https://pic3.zhimg.com/80/v2-459dae7a1abab21d2b2c7519441a049e_720w.jpg)

**首先解决两积分之比这一项**：

不难发现，原本的渲染方程现在变为了对积分域上的Light项取平均，换个说法，就是先对环境贴图做了个模糊处理，材质越glossy，积分域越大，图像就越模糊：

![img](https://pic2.zhimg.com/80/v2-2bb62cc3536e1b2a82bf7c70734541d5_720w.jpg)

因为模糊对象是环境贴图，所以这个模糊操作是可以在渲染之前就完成的，即所谓的**pre-filtering**。我们可以在渲染前对环境贴图进行多级模糊，和MipMap一样，到真正的渲染环节，依据场景物体的材质确定模糊等级（通过插值保证级与级之间的连续），做一次查询就可以得到我们想要的结果

更形象一点，就如下图所示

![img](https://pic1.zhimg.com/80/v2-fcf12c947dbbfa9a2c56d9619fdf6944_720w.jpg)

多次采样后用pdf求平均得到的值 ![[公式]](https://www.zhihu.com/equation?tex=%5Capprox) 对采样对象滤完波查询一次（在镜面反射方向)得到的值，没毛病

（p.s. 老师上课讲的lobe是反射波瓣，就是图中pdf的采样区域，brdf的形状）

| Q：spherical map每个像素表示的立体角不一样，那是不是不应该用统一的fiter size |
| ------------------------------------------------------------ |
| A：没错，滤波的核的大小的单位是立体角，是在对一个球面做滤波  |
| Q：漫反射是不是对整个环境贴图求平均                          |
| A：这么想也不是不行...实时渲染中的漫反射是一种很特殊的情况，它的的lobe是个半球面，所以直接沿着法线方向去查就可以了，至于diffuse的lobe慢慢变小会变为glossy的情况，真正在实现的时候会把diffuse单独处理，所以也不是什么问题 |

这样一来，我们就解决了环境光项的问题。

**此时的渲染方程还剩下一个brdf部分尚未解决**：

对于这个部分，我们仍可以用预计算替代实时采样，但考虑到微表面的BRDF可能会涉及**菲涅尔项**和**法线分布**等至少五维（粗糙度, r, g, b, 角度（菲涅尔项曲线的变化与角度变化相关关），总共五维）的数据处理，直接暴力预计算肯定是不可取的，只好通过一些近似来降低维度，以此来简化预计算

让我们先来复习一下101中微表面理论提到的几个近似：

![img](https://pic3.zhimg.com/80/v2-969107afa61013adf70b7ae013c3664e_720w.jpg)

菲涅尔用的Schlick近似，认为菲涅尔项与基础反射率 ![[公式]](https://www.zhihu.com/equation?tex=R_0) 和入射角有关；法线分布的Beckmann近似，认为该项与表面粗糙度与 ![[公式]](https://www.zhihu.com/equation?tex=%5Ctheta_h) （半角与法线的夹角）有关；而在实时渲染中，因为入射角、反射角以及入射角和反射角的半角 度数差别不大，可以近似的看成一个角， ![[公式]](https://www.zhihu.com/equation?tex=%5Ctheta_h) 又能通过这三个角转化得到，所以角度部分可以认为是一个维度，现在，BRDF项的储存就由**五维变成了三维**

<img src="F:\计算机图形学\games202\26.png" style="zoom: 33%;" />

三维还是不太好存，能不能再压呢？来看下面这个化简

![img](https://pic1.zhimg.com/80/v2-cc3bba0a310968dd56f26ffa3d495a0c_720w.jpg)

看起来很复杂，其实还是比较简单的。通过这个操作我们把基础反射 ![[公式]](https://www.zhihu.com/equation?tex=R_0) 从积分里拆了出来，消除了原方程对它的依赖，那么现在剩下需要预计算的就只剩下roughness和角度两个变量了，直接将预计算结果储存为一张二维的纹理，之后要用的时候直接查表就完事了

<img src="F:\C++代码资料\Fig-DS\100.png" style="zoom:33%;" />

（p.s.实时领域一般会把积分号写成求和号，但里面的内容是一样的）

![img](https://pic3.zhimg.com/80/v2-4e293aab4736149fd63c43f8af42624a_720w.jpg)

可以看到，即使做了这么多近似，结果还是非常令人满意。这也是Unreal引擎做PBR的基础

| Q：Fresnel项需要预计算么？                                   |
| ------------------------------------------------------------ |
| A：Fresnel项被拆开了，可以说只有一部分需要预计算             |
| Q：这个预计算结果是固定的吗？                                |
| A：是固定的，只要是同种类brdf都可以用                        |
| Q：用Microfacet GGX，参数会多么？                            |
| A：不会                                                      |
| Q：深度学习在实时渲染领域有没有什么其他的应用？除了DLSS      |
| A：现在甚至连降噪都不会用深度学习，它在实时渲染中并不怎么成功，实在太慢了 |
| Q：IBL适用于什么场景？                                       |
| A：适用于任何你想用它的场景，但当光源和你的物体有确定的距离的时候，就不能再这么使用了（因为IBL假设光源无限远） |
| Q：积分里的F怎么计算？                                       |
| A：不用算，BRDF的式子里包含F，分子分母消掉了                 |

### 环境光阴影的实现难点

前面我们介绍了如何在忽略阴影的情况下计算环境关照，那么如果现在不忽略阴影，我们又该如何计算呢

很可惜，以目前的技术来说，实现环境光下的阴影是基本不可能的一件事，尤其是对于实时来讲，它会变得更为困难。这主要体现在两个问题上，其一是**多光源问题（many-light problem）**，如果将环境光理解为四面八方无数的小光源，那么生成阴影也就意味着需要在每个小光源的位置处生成一张对应的shadow map，这么做的代价是不可估量的；另一个问题是**如何采样**，就算通过某种手段我们得到了多光源的shadow map，我们也很难获取着色点周围所有方向上的遮挡情况，那么为了计算Visibility项我们只好盲目的进行采样，在生成一大堆样本后慢慢处理。同时，我们也无法从渲染方程中将Visibility提取出来，因为对于环境光，

 ①无法满足足够小的积分域

lighting的support由于是环境光在整个半球积分

②无法满足低频的BRDF  

glossy变化较高频     这两个提取条件它一个都无法满足，所以，常规的做法到这里都会变得寸步难行

**Recap**

卷积：对图像每个像素都在一定范围（卷积核）内做加权平均的操作，算是一种滤波的操作

![img](https://pic4.zhimg.com/80/v2-6d5df8f0d07857dc54b250f4c147b2bf_720w.jpg)

在时域内的卷积操作就相当于在频域内的相乘（原图频谱×卷积核频谱），而相乘结果经过逆傅里叶变换就能得到基于原图的模糊效果

用数学来表示，就是对两个函数的乘积求积分（product integral）：对于两个函数乘积求积分，相当于两个函数在时域上进行卷积

![img](https://pic1.zhimg.com/80/v2-74299c35e9ff476b347b003a1174308c_720w.jpg)

相当于在频域上让两个信号相乘，==最后输出的频率取决于积分前的两个函数的最低频率==

## 球谐函数SH

### 定义

球谐函数（Spherical Harmonics）其实就是定义在球面坐标系中的一系列**二维基函数**，每个基函数都可以用 *勒让德多项式* 写出来，我们不需要了解勒让德多项式是什么（那毫无意义），只要能看明白下面这张可视化就行：

**SH**是定义在球面函数不同方向上的二维函数，具有不同的频率，每种频率上有不同的二维基函数，很适用于通过它去分析球面上函数的性质。

![img](https://pic2.zhimg.com/80/v2-f36d4615e2954296d62304315dacc8f5_720w.jpg)

图中蓝色表示的是正值，黄色表示的是负值，颜色深浅表示的是**函数值的大小**，越深越小，而形状则表示**频率的大小**，每一层（l相同时，频率时相同的）

图的最左边标明了球谐函数的**阶数**，第 ![[公式]](https://www.zhihu.com/equation?tex=l) 阶球谐对应有 ![[公式]](https://www.zhihu.com/equation?tex=2l%2B1) 个基函数，前 ![[公式]](https://www.zhihu.com/equation?tex=n) 阶一共有 ![[公式]](https://www.zhihu.com/equation?tex=n%5E2) 个基函数，而图的最下边 ![[公式]](https://www.zhihu.com/equation?tex=m) 则对应了球谐函数的**序号**，第 ![[公式]](https://www.zhihu.com/equation?tex=l) 阶对应的序号范围为 ![[公式]](https://www.zhihu.com/equation?tex=%5B-l%2Cl%5D)

有了这一系列概念，再来看球谐函数的展开公式， ![[公式]](https://www.zhihu.com/equation?tex=f%28x%29%3D%5Csum_i+c_i%C2%B7B_i%28x%29) ，其中 ![[公式]](https://www.zhihu.com/equation?tex=B_i%28x%29) 是球谐函数，可以认为已知， ![[公式]](https://www.zhihu.com/equation?tex=f%28x%29) 是原函数， ![[公式]](https://www.zhihu.com/equation?tex=c_i) 是球谐系数，那么原函数就可以储存为一个 ![[公式]](https://www.zhihu.com/equation?tex=i) 维向量 ![[公式]](https://www.zhihu.com/equation?tex=%28c_1%2Cc_2%2C%C2%B7%C2%B7%C2%B7%2Cc_i%29)

计算球谐系数的过程称为**投影**，任何一个 ![[公式]](https://www.zhihu.com/equation?tex=f%28x%29) 都可以求出其在 ![[公式]](https://www.zhihu.com/equation?tex=B_i%28x%29) 上的投影 ，其计算方法如下（product integral)：

![img](https://pic3.zhimg.com/80/v2-c9fc39b95b0d6cdae271de2f0a685756_720w.jpg)

定义在球面上的一个的函数  ![[公式]](https://www.zhihu.com/equation?tex=f%28x%29) 如果使用SH表示，则其中任何一个基函数前面的系数ci可以通过这个计算方法来求出。

整个environment map投影到一个基函数上是一个值ci，从各个方向四面八方来的环境光照即**f(w)**投影到**前n阶**（L）的**基函数**，再用**前n阶**的SH去恢复这个函数，就可以恢复出最低频的信息。

**计算漫反射环境光照时，对于渲染方程中BRDF项的近似：**

<img src="F:\计算机图形学\games202\27.png" style="zoom: 33%;" />

已知球谐系数，还原原函数的过程称为**重建**（实际上可以理解为做了一系列的点乘），使用的基函数越多，展开的阶数越高，重建的细节的越多，还原的效果就越好，如图

![img](https://pic3.zhimg.com/80/v2-02c892918e230bcbaff87d044eddffb6_720w.jpg)

当我们使用Spherical Map作为环境贴图时，环境光信息被定义在一个球面坐标系内，这时候我们就可以用球面谐波函数对其展开近似，而当brdf为diffuse时，**渲染方程**的 ![[公式]](https://www.zhihu.com/equation?tex=f_r) 项只有低频信息，相当于一个低通滤波器，那么无论环境光多么高频，最后乘积的结果仍是低频，所以此时只需用三阶的球谐函数就能对于渲染方程的 ![[公式]](https://www.zhihu.com/equation?tex=f_r) 项做到很好的近似，这样一来通过预计算虽然牺牲一定储存空间（存16维向量)，但它既免去了采样的过程，又为后面的PRT奠定了理论基础，显然还是很划算的

**计算漫反射环境光照时，对于渲染方程中光照项的近似：**

<img src="F:\计算机图形学\games202\28.png" style="zoom: 33%;" />

通过先分析BRDF的频率，再去分析要用多少阶的SH近似光照，由于 ![[公式]](https://www.zhihu.com/equation?tex=f_r) 项只需用三阶（低频)的球谐函数做到很好的近似，那么对于渲染方程中diffuse brdf前面的光照项，也只需要前三阶的SH函数去近似即可。

### 性质

在正式介绍PRT之前，还需要补充球谐函数的一些优良性质

**正交完备性**

球谐函数中任意两个基函数之间都满足相互正交，即其中任意一个球谐函数向另一个球谐函数的投影结果都是0，而如果向自己投影，则结果是1：

![img](https://pic1.zhimg.com/80/v2-f628735e10280bb079f3b2e8963144f0_720w.jpg)

**旋转不变性**

对任意函数进行旋转，就相当对球谐展开的基函数进行旋转，旋转后的基函数虽然不能再被称为基函数，但它仍旧可以由同阶的基函数的线性组合表示出来，这就意味着不论怎么旋转原函数，我们都可以立刻得到其新的球谐系数

## PRT

现在有了SH，就可以将Visbility项考虑进来了

![img](https://pic1.zhimg.com/80/v2-15ff4038d6ec6b997a18d75a5b98b058_720w.jpg)

（brdf可以由入射角、出射角、入射方位角和出射方位角定义，所以可以写成图中的四维的形式，详情参考101 p17）

一般思路是将环境光项、Visibility项和brdf项全都描述为球面函数（这里为了方便理解使用cube map展示），然后逐像素相乘，最后相加。这种思路可谓一点都没体现球谐函数的优势，且不论三张贴图的存储，对每个shading point，光逐像素计算就要花费很多计算，远远满足不了实时的要求

<img src="F:\计算机图形学\games202\29.png" style="zoom: 33%;" />

因此我们引入了PRT（Precompute Radiance Transfer，基于预计算的辐射传输），其核心思想是将渲染方程分为lighting（环境光项）和lighting transport（Visibility&brdf）两部分，假设场景中只有lighting部分会发生变化（旋转or更换光源），而lighting tansport部分固定不变，可以被认为是一个球面函数。因为lighting部分可以被球谐展开，所以旋转操作并不会造成多大影响（旋转不变性）， lighting tansport也可以被表示成基函数的形式（可以在渲染之前被预计算出来），即使更换光源，也只要在预计算中多计算几个光源就行，那么这两部分就都可以被球谐展开，从而在预处理中完成部分计算:

**计算方法Ⅰ**

第一种计算diffuse的方法，因为对于diffuse的情况，brdf几乎可以被认为是一个常数，所以直接将其提到积分号外面

![img](https://pic4.zhimg.com/80/v2-a17e207f397a377e8f7f19a1c0b0ca63_720w.jpg)

再将 ![[公式]](https://www.zhihu.com/equation?tex=L%28i%29) 写成球谐函数的形式，因为实时渲染中求和和积分次序可以任意交换，所以原式化简如下：

![img](https://pic2.zhimg.com/80/v2-2ac3cedcf40b03a2b7bd206d24b1a519_720w.jpg)

对于这个约等式的积分部分，一共有两种理解方式，一种是将其理解为一个投影操作，将light transport投影到某个基函数上，得到的是它在环境光照球面坐标系内的球谐系数，那么最后的渲染方程就变为了两个向量的点乘（ ![[公式]](https://www.zhihu.com/equation?tex=%5Csum+l_iT_i) 其实就是点乘）

![img](https://pic2.zhimg.com/80/v2-ea5ff2007bcb49d8bf4c6a103b6c3d25_720w.jpg)

<img src="F:\计算机图形学\games202\30.png" style="zoom: 50%;" />

对于 固定不变的部分lighting tansport，场景中任何一个shadingpoint都可以投影到基函数上去。

最后，对于任何一个shadingpoint，只需要计算 li 与Ti的点乘就可以了。

**局限性：**

1. 由于我们认为lighting tansport部分固定不变，那么其中Visibility项也是固定不变的，那么就是认为任何一个shadingpoint看向四面八方，看到其他遮挡物遮挡住light的方式完全一样。意味着场景不可以发生改变。

2. 处理不了一种预计算的室内的光源发生旋转的情况：但SH具有旋转不变性，即对于任意一个light的旋转相当于我们对于SH基函数的旋转，任意一个SH基函数的旋转，我们都可以利用同阶的基函数的新的线性组合的形式得到。

另一种理解方式是将 ![[公式]](https://www.zhihu.com/equation?tex=B_i%28i%29) 理解为一盏光（**light**），那么这里对于light transport的积分就相当于重算了一个渲染方程，算的是这些球谐函数所描述的环境光作用于物体的结果，最后以 ![[公式]](https://www.zhihu.com/equation?tex=l_i) 为权重叠加求和，得到最终的重建结果（下图中红色代表正值，蓝色代表负值)

![img](https://pic2.zhimg.com/80/v2-ea5ff2007bcb49d8bf4c6a103b6c3d25_720w.jpg)

![img](https://pic1.zhimg.com/80/v2-3da4506d1f9fb520b0703ff18cfd1124_720w.jpg)

**时间复杂度：**

shadingpoint相当于每个几何形体得顶点，对于每个几何形体得顶点计算得到lignt transport得向量。实际计算的时候可以先得到每个顶点得shading result再对三角形内部的点进行插值。

<img src="F:\计算机图形学\games202\31.png" style="zoom: 50%;" />

**计算方法Ⅱ**

与计算方法Ⅰ不同，计算方法Ⅱ彻底将lighting和light transport部分分开考虑，分别对他们球谐展开，设$c_p$为lighting的球谐系数，$c_q$为light transport的球谐系数：

![img](https://pic1.zhimg.com/80/v2-7ce34b498261216e71c15c492b06e190_720w.jpg)

代入渲染方程，同计算方法Ⅰ，交换求和与积分次序，将两个球谐系数提出来

![img](https://pic3.zhimg.com/80/v2-efd93c25dad1daacb81701d48e7a117a_720w.jpg)

可以发现结果变为了一个双重求和的形式，并且乍一眼看上去时间复杂度还似乎从计算方法Ⅰ的 ![[公式]](https://www.zhihu.com/equation?tex=O%28n%29) 变为了 ![[公式]](https://www.zhihu.com/equation?tex=O%28n%5E2%29)

实际上，因为球谐函数的正交性，只有当p=q的时候，也就是lighting和light transport用了同阶基函数时， ![[公式]](https://www.zhihu.com/equation?tex=%5Cint_%7B%5COmega%2B%7DB_p%28i%29B_q%28i%29%5C+dw_i) 才会等于1，其他时候都等于0，根本不用纳入计算范围，就好比一个二维矩阵只计算它对角线上的元素，其算法复杂度仍然是 ![[公式]](https://www.zhihu.com/equation?tex=O%28n%29)

**Diffuse总结**

纵观PRT的整个计算过程，不管是哪种计算方法，它都只需要经过部分的预计算，就能把原先的逐顶点 / 逐像素操作转化为向量的点乘，这对于性能来说绝对是成百倍的提升，并且我们还可以从下图看到，它不仅适用于计算带阴影的环境光，还适合做多次bounce的间接光照预计算，结果同样非常不错（关于间接光预计算后面会有详细说明）

![img](https://pic3.zhimg.com/80/v2-8df4148962f7dfcb1b8df314aa77424a_720w.jpg)

### Glossy Case

对于glossy的材质，brdf项就不能简简单单的当做一个常数去处理了，因为当观察glossy材质的时候，每个不同的视角得到的shading结果都不一样，所以计算其光路还需要将视角关联进来（四维brdf：入射角、出射角、入射方位角、出射方位角）

那么如果这时候再像之前计算方法Ⅰ那样，将light transport投影到lighting的基函数上，投影的结果就不再会是一个球谐系数了，而是一个关于出射方向o的函数 ![[公式]](https://www.zhihu.com/equation?tex=T_i%28o%29) ，换句话说，是一组球谐系数

![img](https://pic1.zhimg.com/80/v2-108daaeec9e3857c506d7329a57f9138_720w.jpg)

对$T_i(o)$球谐展开， ![[公式]](https://www.zhihu.com/equation?tex=T_i%28o%29%5Capprox+%5Csum+t_%7Bij%7DB_j%28o%29) ，对于T_i(o)，我们可将其投影到不同的观测方向上的 SH上面去

代入原式

![img](https://pic4.zhimg.com/80/v2-dd3868b8bb7e4ddb808892802e3e9b3b_720w.jpg)

于是结果就从原来的向量点乘变为了一个向量和一个矩阵的乘法

矩阵理解方式1： ![[公式]](https://www.zhihu.com/equation?tex=T_i) 的每个基函数都对应一组球谐系数，矩阵大小为基函数阶数n*视角采样次数m

矩阵理解方式2：对任一出射方向 / 视角上的 ![[公式]](https://www.zhihu.com/equation?tex=T_i%28o%29) 球谐展开，会得到一组基函数的球谐系数，最后把所有方向上对应的基函数vector组合在一起，就形成了一个矩阵。矩阵大小为视角采样次数m*基函数阶数n

矩阵理解方式3：我们最后得到的结果是不同方向上的radiance，是一个向量，而lighting部分球谐展开得到的也是一个向量，只有向量乘以一个矩阵才能最后得到一个向量，所以light transport部分球谐展开得到的是一个矩阵（倒推法）

![img](https://pic1.zhimg.com/80/v2-383609d4a0cf08798d6867a4bfd1f20c_720w.jpg)

所以对于glossy材质，使用PRT的效率会比diffuse差很多，四阶的情况下，diffuse的每个shading point只要乘一个16维向量就够了，而glossy必须乘以一个16*16的矩阵，五阶就是25*25，这在储存上带来的压力增长可想而知

### Inter Case

之前提到，PRT还适合做一些多次bounce的间接光照预计算，那么它这么做的理论依据是什么呢？

其实非常简单，我们把light transport部分理解为光的传播路径，再用正则表达式把它描述出来

![img](https://pic4.zhimg.com/80/v2-877b3a760f9995446b3537864dd55967_720w.jpg)

<img src="F:\计算机图形学\games202\32.png" style="zoom: 50%;" />

Light打到内壁specular上在反射到diffuse上被我们人眼看到叫做**LSDE**，即表格中最后一种情况。

可以看到，所有光线的传播路径的起点和终点都是光源light和摄像机，不论中间有多少次bounce，最终的表达式都可以被描述为light和light transport两部分，所以我们只需要预计算出light transport，就可以得到最后的shading result（计算方法参考Diffuse计算方法Ⅰ的第二种理解方式，结合Ray Tracing之类的算法就可以完成）。而这样一来，因为所有复杂的计算都被集中在预计算中处理掉了，实际渲染所消耗的时间自然就与light tranport的复杂度无关了

下图为各种不同的BRDF的渲染结果，spatial varying BRDF指的是各点具有不同brdf的材质，如生锈的铁器等

<img src="https://pic2.zhimg.com/80/v2-cd0519cebaf3bd073837d348a370028d_720w.jpg" alt="img" style="zoom:50%;" />

### PRT的局限

PRT虽然可以很好的实现带有阴影的实时环境光渲染，但它也有它自己的局限性，主要体现在两方面

首先是对场景的要求。之前我们假设light transport不变，相当于默认了这一部分对于场景是一种自带的属性，也就是说如果要使用PRT，渲染对象就必须具备**静态场景、动态光源**这一条件，如果场景中的物体发生移动，物体原先的阴影就会因为Visibility项固定不变而留在原地，而如果物体的材质发生变化，或者物体发生了形变，则会得到错误的结果

其次是对材质的要求。因为球谐函数在描述高频信息时需要非常高阶的基函数才能完成重建，所以一般PRT只适合做一些较为低频的情况，比更高频得glossy材质重建不了（试想用26阶球谐重建glossy材质，最后得乘一个 ![[公式]](https://www.zhihu.com/equation?tex=26%5E2) 阶的矩阵，676*676，这是何等恐怖的储存压力)

![img](https://pic2.zhimg.com/80/v2-2aa32d6cb11fa57c2c048fbbf3d52951_720w.jpg)

| Q：怎么做spatial varying的brdf预计算                         |
| ------------------------------------------------------------ |
| A：PRT关注的更多的是已知brdf的预计算，一般人们会用一些诸如柏林噪声之类的可控制噪声来得到spatial varing brdf |
| Q：glossy材质中的视角方向怎么决定？                          |
| A：不是视角方向怎么决定，而是要在预计算中把所有视角方向的球谐都算出来，至于矩阵不能无限大 |
| Q：预计算是写在光栅化里面么？                                |
| A：预计算是一个独立的程序，会有存储和读取的过程              |
| Q：预计算可以理解成伪材质吗？                                |
| A：可以，可以理解为伪材质的一部分                            |

### 小波函数（Wavelet）

为了解决SH在频率上的局限，科学家研究出了一些其他不同的基函数，如Zonal Harmonics，Spherical Gaussian（SG），Piecewise Constant等等等等，而小波函数也是其中之一

不同于球谐函数，小波函数是定义在图像块上的一系列基函数，不同的小波函数具有不同的定义域，如图

![img](https://pic1.zhimg.com/80/v2-538d846fc56fd7ee06d2370b1bd8f888_720w.jpg)

当用小波函数对原函数进行压缩的时候，我们也不再会采用SH那样的截断方法，而是选择将原函数投影到全部基函数上，通过舍去大量接近0的小波系数，保留部分基函数从而来完成近似。

因为小波函数是定义在图像块上的基函数，所以为了防止重建后的图像出现接缝，我们一般会使用cube map记录环境光照。以二维Haar Wavelet为例，从下面的gif可以看出，小波函数对图像的压缩过程是先把压缩区域分为四个部分，将低频信息放在左上角，高频信息分波段填充剩余部分，随后对左上角的低频信息继续递归执行之前的步骤（四叉树）

![动图封面](https://pic1.zhimg.com/v2-c63b7d49bd4eb0d9e4936515bc92b858_b.jpg)



从图中我们很容易观察到，随着压缩程度的越来越大，cube map会变得越来越灰，这恰恰说明了经过小波变换后原图像会舍去大量次要信息（只保留0.1% - 1%的有效信息），从而高效地得到一个**全频段**的压缩结果

值得一提的是，虽然小波函数解决了球谐函数的频率限制，但它同时也放弃了球谐的一些好的性质，比如SH的旋转不变性，使用小波函数就无法做到像之前那样随意转动灯光，每次旋转都必须重新进行计算（这就涉及到dynamic scene的PRT研究了，单论基函数的话小波函数还是非常不错的）

## 图像空间方法

### 反射阴影贴图（RSM）

**基本思路**

既然实时全局光照只计算比直接光照多一次bounce的间接光照，那么问题就自然分为了两个部分：

1° 场景中哪些表面会被直接光照影响，反射出间接光

2° 如何计算这些表面对着色点p的贡献

对于这两个问题，RSM的思路是通过shadow map获取直接光照的影响区域，再根据shadow map的分辨率将这些区域微元化，把其中每一个像素（或者说surface patch）都当做一个次级光源进行计算，如图

![img](https://pic2.zhimg.com/80/v2-9688acdb02b3cc342291c570b7a90555_720w.jpg)



这个概念其实和离线渲染中的虚拟点光源（Virtual Point Light，VPL）有些类似，唯一的区别在于，这里RSM会将所有次级光源的表面设为diffuse，以摆脱这些surface patch对视角方向的依赖（如果不这么设置，次级光源是glossy的话，计算量会变得非常恐怖），又因为我们无法对每个次级光源都生成一张阴影贴图，所以在实时渲染中间接光通常不会考虑Visibility的大小，那么现在连接pq，我们所要计算的虚拟光源贡献就是在q点处出射的radiance大小

![img](https://pic1.zhimg.com/80/v2-2e60ae1cfc46995ce73de5d70ccc0bd0_720w.jpg)

上式中，因为光源面积是阴影贴图上的一系列像素，所以可以直接当做 ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bd%7DA) 处理

由brdf定义 ![[公式]](https://www.zhihu.com/equation?tex=f_r%28%5Comega_i%5Crightarrow%5Comega_o%29%3D%5Cfrac%7BdL%28%5Comega_o%29%7D%7BdE%28%5Comega_i%29%7D) ，得 ![[公式]](https://www.zhihu.com/equation?tex=L%28q+%5Crightarrow+p%29%3Df_r%C2%B7%5Cfrac%7B%5Cphi%7D%7BdA%7D) ，代入渲染方程，原式化简如下

![img](https://pic3.zhimg.com/80/v2-709961808871586438b1727b55371992_720w.jpg)

又由假设中的diffuse次级光源，可知 ![[公式]](https://www.zhihu.com/equation?tex=f_r) 是一常数，合并参数，最后就可以得到下面这个式子（老师的写法）：

![img](https://pic4.zhimg.com/80/v2-ddff384a491c762ffc3d4ac5967ebbff_720w.jpg)

至于老师说的paper里的那个分母中的4次方，则是因为分子未做归一化导致的，后来在p9开头有做澄清（硬盘装不下.jpg）

两个式子都没有错，这里把字母全都做了一个统一，方便比较：

![img](https://pic3.zhimg.com/80/v2-593a42c6eb5d19134fa6757383a76c9a_720w.jpg)

**算法优化**

试想按照前面的思路去计算场景中一个点的间接光，如果每个着色点所使用的shadow map分辨率都是512*512，那就意味着要设置20多万个虚拟光源，这显然非常不合理；并且我们从下图也很容易看到 ，场景有一些点是不可能对目标着色点产生影响的（如 ![[公式]](https://www.zhihu.com/equation?tex=q%27) 点和 ![[公式]](https://www.zhihu.com/equation?tex=p) ），计算它们纯粹是在浪费性能

![img](https://pic3.zhimg.com/80/v2-1ba8d68fd747f4d5714841b3c73ce6a2_720w.jpg)

于是为了解决这个问题，作者不再采用逐一计算虚拟光源的方法，而选择以着色点为中心，做一个有侧重的选取

![img](https://pic4.zhimg.com/80/v2-a780942bc99adbb27d20489ca2311ca3_720w.jpg)

他认为在shadow map中 距离着色点越近（或深度越接近）的虚拟光源带来的贡献越大，那么就只要多选取一些离着色点相近的次级光源，再引入一个与SM距离相关的权重来弥补稀疏采样带来的误差（越远越稀疏，权重越大），就能对最终的结果做出一个很好的近似（一般一个shading point只要400次采样就足够了，直接在原先基础上降了3个数量级，优化幅度还是非常大的）

**RSM总结**

综上所述，实现RSM一共需要储存四种信息：

① 光源空间的深度值（shadow map）；② 世界坐标，用来比较距离；③ 法线，排除不可能对目标着色点产生影响的点；④ 光源光强flux

![img](https://pic1.zhimg.com/80/v2-ce370f6b7e8d2b19b2170f39638d9eac_720w.jpg)

在实际应用中，RSM通常被用来做一些小型的单光源全局光照（如下面这张gif里的手电筒），一方面是因为它思路比较直接，实现起来比较方便，另一方面也是因为小型光源的shadow map的储存压力小，使用RSM可以以非常低的性能代价给画面带来质的提升

![动图](https://pic1.zhimg.com/v2-fea0fab09c073632b2a46b2fba1bd6cc_b.webp)

但是同样也是因为这个原因，使得RSM在光源数增加的时候更容易遇到性能瓶颈（因为需要储存更多的shadow map）

另外在其他方面，RSM也还存在着一些问题，比如次级光源的diffuse，忽略Visibility项，低采样率和质量的取舍等等，这些都会或多或少对结果造成一定影响，导致RSM在实际开发中的应用频率并不高

即使如此，作为一个经典的算法，RSM仍对后人带来了相当深远的启发，包括后面要讲的LPV，也是建立在其基础上才被提出的，因此其中的思想仍然值得我们去学习和借鉴

## 三维空间方法

### LPV

参考（其中包括Visibility的解决方法）：

![img](https://pic3.zhimg.com/v2-0a9c8e3c378fd0547a6a5366d6c32aea_180x120.jpg)

Light Propagation Volumes（光照传播体积），最早是由 CryEngine3 提出的一种基于RSM和球谐函数的实时全局光照技术，其核心思想是通过将场景划分为一系列三维网格（体素化）来模拟光线的传播，随后利用其Irradiance在传播过程中保持恒定这一特征，计算出每个shading point上的间接光照。这一创造性的方法不仅在速度和质量上有着非常好的表现，还同时解决了一部分RSM带来的问题，下面就来介绍它的具体做法

- **生成（Generation）**

第一步很简单，利用光源的shadow map完成次级光源的定义即可。在这一步可以通过采样对次级光源的数量做出一些简化，从而给算法带来一定优化

- **注入（Injection）**

对整个场景进行体素化，并将虚拟光源转化为对应体素的属性。一块体素可能对应多个虚拟光源，叠加其内部所有虚拟光源即可得到当前体素的Radiance信息

在存储过程中，由于Cube Map的开销过于庞大，我们可以使用球谐函数对其进行压缩，工业界一般认为**两阶SH就能做到很好的拟合**

![img](https://pic1.zhimg.com/80/v2-e44a1387e235fb82cb13efae1d653a40_720w.jpg)

- **传播（Propagation）**

对于每一个体素，依据其储存的Radiance分布，计算它周围六个体素的radiance，然后分别对它们使用SH进行简化。对角的体素可以被多步传播覆盖到，因此不做考虑

![img](https://pic2.zhimg.com/80/v2-57097f5dc6ae9caac7cc520ee9784e99_720w.jpg)

计算完成后，再算这六块体素各自 除了原体素相邻面以外的 另外五个格子，如此迭代，直至传播的radiance趋于稳定

- **渲染（Rendering）**

对场景中任意着色点，找到其所在的体素并叠加所在体素中所有方向的radiance后正常渲染即可

![动图封面](https://pic3.zhimg.com/v2-c59268a2f57a5a6441e9c7e90f846e66_b.jpg)

LPV提供的这种实现全局光照的方法**不需要任何的预计算**，因此可以支持各种变化的场景，做到真正的”实时“。不过，它有时候也会存在一些问题，如图，当渲染的几何对象小于体素大小，即体素划分精度不足时，会出现漏光的现象

![img](https://pic4.zhimg.com/80/v2-3b992f9a4abb73e6397036118a7fb527_720w.jpg)

![img](https://pic1.zhimg.com/80/v2-744c174d320fd9c5cae527894677ff54_720w.jpg)

这是因为在LPV注入的时候，我们假设所有的Radiance都是由体素中心发出的，因此对于下图中原本位于薄墙左侧的点p，就会被强行移动到右侧，产生漏光。为了解决这个问题，我们可以选择提高体素精度，但这还是会面临一个性能与质量之间的取舍

![img](https://pic3.zhimg.com/80/v2-d2c72b874aa91fe6fac43bbc068ea176_720w.jpg)

另外，在场景较大、光源较多的情况下，LPV的计算压力也会随之上升，关于这一点，可以使用类似LOD的级联方法进行加速：

![img](https://pic3.zhimg.com/80/v2-fe3e690d4a19d21b13a3e1167e144356_720w.jpg)

| Q：体素划分一般多大比较合适？                                |
| ------------------------------------------------------------ |
| A：至少比场景分辨率少一个数量级                              |
| Q：一块体素会记录其他多个体素的传播贡献吧？                  |
| A：当然，每个格子都会对它周围 6个/5个 格子产生贡献，最后累加 |
| Q：传播过程中会不会一直不稳定传播，达不到稳态而无法停止？    |
| A：肯定是会达到稳态的，就像向水面投一块石头产生的波纹，没有外界影响的话最后肯定是会收敛的 |
| Q：LPV会假设次级光源是diffuse的吗？                          |
| A：会，只要是用SH压缩，渲染glossy表面都会造成强烈模糊，所以一般只要用了SH都会假设diffuse |

### VXGI

与RSM和LPV类似，Voxel Global Illumination（体素全局光照）也是一个基于体积渲染的2-pass实时全局光照算法，但它与二者的区别在于：① VXGI 会在对场景离散体素化之后，再对数据做一次**稀疏八叉树划分**，所以从一开始，它的“次级光源”就是一系列体素；② 在渲染过程中，VXGI 会采用**Cone-Tracing**的方式计算间接光的贡献，在速度方面会比LPV慢很多

![img](https://pic2.zhimg.com/80/v2-cf01187dd97a685d44ae8b84e37e0b31_720w.jpg)

下面来具体介绍这个算法的执行步骤：

- **Light-Pass**

VXGI 的第一个pass主要关注场景中哪些表面会被直接光照照亮，以及间接光照的反射方向。和LPV的注入过程不同的是，虽然它们都是以体素为储存单位，但 VXGI 记录的是直接光源的**入射方向区间**和体素对应的受光表面的**法线方向区间**，结合材质，VXGI 能够轻松的算出间接光照的分布（即直接光出射方向，反射波瓣），而在算完最低层级的体素之后，将当前层级的八个叶子结点相加，就可以计算更高一级体素的间接光照分布了（diffuse的情况比较特殊，下面会提）

![img](https://pic3.zhimg.com/80/v2-1fbec437a7c484688527b116e0afa5ee_720w.jpg)

比起LPV用SH压缩记录虚拟光源信息，这种计算方法可以支持glossy，并且结果会更加准确

- **Camera-Pass**

在第二个Pass，VXGI 就要开始考虑真正的渲染问题了。通过第一个Pass我们可以知道Cone-Tracing的间接光照投射方向与锥角大小，那么对于glossy的表面就可以像Ray-Marching那样，只要基于一定Ray-Cone Footprint（理解为锥截面大小），到八叉树中相应层级进行查询，就可以得到范围内所有shading point的**irradiance**大小了（其实和mipmap一模一样，只不过将纹理查询转化为了子树遍历问题）

![img](https://pic4.zhimg.com/80/v2-90723a627327eed26867fbbc2b74adef_720w.jpg)

而对于diffuse表面就比较特殊了，VXGI 通常会将出射方向看做若干圆锥，而忽略锥与锥之间的间隙（影响并不会很大），暴力求解，但这样一来diffuse就会比glossy多一层循环，效率比起其他方法自然也会更差

![img](https://pic3.zhimg.com/80/v2-ffb862915ced4b88be0a3aa3700a8c5a_720w.jpg)

总的来说，同样作为一种体积渲染方法，VXGI 的渲染结果质量非常好，有时候甚至可以做到与光线追踪相近的效果，但缺点是开销太大，且Light-Pass前的体素化会有一定预处理需求，所以它的实际应用也受到了很大的限制

**基于图像空间**：RSM

**基于世界空间**：LPV,VXGI

## 基于屏幕空间方法

**屏幕空间方法起始用到的信息**：以camera角度为视角 、在做全局光照前屏幕上得到的一个直接光照

屏幕空间实时渲染，是指利用在所有pass渲染完成之前各个帧缓冲中的信息，对已渲染结果加以修改的渲染方法。伴随着延迟渲染的兴起，更多的信息得以在屏幕空间取得，因此也延伸出许多不同的算法，这些算法一般都具有如下特点：

- 能够很方便的支持各种滤波算法
- 解除了场景复杂度对算法的限制
- 会有不同程度的信息丢失（因为只能获得一些相机观察得到的信息，所以遮挡越多，越有可能发生信息丢失）

本节将针对屏幕空间的全局光照，介绍SSAO，HBAO，SSDO、SSR共四种GI近似方法

### AO（环境光遮蔽）

在开始这个话题之前，首先要明白AO是什么，它和法线、RGB这类信息一样，也是场景的一种属性，描述的是物体与物体之间环境光互相遮挡的程度。在场景中加入AO信息，可以让物体相交处的阴影更加脚踏实地，从而让整个画面更具立体感

![动图封面](https://pic3.zhimg.com/v2-79d3144bf664140b3876be6244453bda_b.jpg)



在计算全局光照过程中，由于我们无法在屏幕空间中直接获得间接光照，所以一般会假设间接光照强度为一个定值，随后通过AO来决定GI的亮度。比如在下图中，左边的shading point的AO比右图小，那么显然左边的间接光就会比右边亮

![img](https://pic3.zhimg.com/80/v2-ea402cf2adb403ca5b1a93a8959cda36_720w.jpg)

**AO背后的数学原理**

有了形象解释，再来看渲染方程

![img](https://pic2.zhimg.com/80/v2-314852267cb80c17d5d2d092789021a5_720w.jpg)

为了方便理解，我们需要再次用之前那个积分近似公式 把Visibility项拆出来，只不过这次我们并不是简简单单的对拆出去的Visibility取平均，而是引入了一个新的概念——投影立体角

![img](https://pic4.zhimg.com/80/v2-06d6ff29ea94968df98656a93d44a62b_720w.jpg)

从图中可以看到，我们原先定义的立体角是在单位球上的一个面积微元， ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bd%7D%5Comega_i%3D%5Csin+%5Cmathrm%7Bd%7D%5Ctheta%5Cmathrm%7Bd%7D%5Cphi) ，如果我们在此基础上，将这个面积微元向x-y平面投影，就会得到一个单位圆上的面积微元，而这块面积我们就称其为投影立体角， ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathrm%7Bd%7Dx_%7B%5Cperp%7D%3D%5Ccos%7B%5Ctheta_i%7D%5C%2C%5Cmathrm%7Bd%7D%5Comega_i) ，不难看出，对单位半球面上的投影立体角求积分的结果，就相当于在求一个单位圆的面积，那么约等式的前半部分就可以理解为是在对 **单位半球面 沿法线垂直向下投影 所得的单位圆内**对可见性按照cos值进行加权平均；而对于式子的后半部分，由于我们假设了间接光照强度是一个定值，且材质BRDF全都统一为diffuse，所以整个后半段积分积出来就是个常数， ![[公式]](https://www.zhihu.com/equation?tex=L_%7Bindir%7D%C2%B7%5Cfrac%7B%5Crho%7D%7B%5Cpi%7D%C2%B7%5Cpi%3DL_%7Bindir%7D%C2%B7%5Crho) （后半段积分是个常数)，这对于积分近似公式也是100%准确的

由上，原式最后可以化简如下

![img](https://pic1.zhimg.com/80/v2-739de189833bc6b37905aa7514b28ca8_720w.jpg)

通过这个式子我们就可以很直观的了解到AO背后的实现原理，即**环境的间接光照来自远处的未被遮挡的光线**

值得注意的是，此处的“来自远处”并不代表着可见判断范围可以无限大，因为在某些特定的封闭场景下（如室内），如果可见性判定范围无穷大， 那么所有光线最终都会被挡住，将会得到一个AO处处为1的结果（没有间接光照）而若判定范围不足，则会造成可见信息的丢失，因此我们为了得到准确的AO，一般都会选取一个合适的判定半径，在一个半球范围内完成操作，这是一个不可避免的trade off

![img](https://pic4.zhimg.com/80/v2-404b527410592dd3130e020394d7631b_720w.jpg)

### SSAO

经过上述分析，我们已经得到了场景AO的计算方法，那么现在的问题就只剩下如何（在屏幕空间中）求Visibility的积分了

对此，SSAO（Screen-Space Ambient Occulusion）的解决方案如下：

- 首先从相机出发，得到屏幕空间的深度信息，写入z-buffer
- 对屏幕空间的任意一个像素（着色点），在以它为中心、R为半径的球体范围内随机寻找数个采样点，判断其可见性
- 当“红点”数量过半的情况下，若该采样点的深度大于它在屏幕空间对应的深度，则认为该点不可见，记可见性为0（下图绿点）
- 计算可见性为1的采样点的占比，作为当前像素的visibility值

在早些时候，屏幕空间渲染还无法获得法线信息，因此那时候SSAO只能通过考虑“红点”过半下的情况，开始考虑AO问题，如第三幅图的情况：有四个红点被挡住，一个点没被挡住，那么 visibility的值为20%来近似AO，并且同时无法使用上面推导的cos对可见性进行加权

<img src="F:\计算机图形学\games202\34.png" style="zoom: 50%;" />

而在延迟渲染普及之后，我们就可以更加准确的在法向半球内采样，进而也能够使用法线与采样点之间的夹角余弦对结果做加权平均

![img](https://pic1.zhimg.com/80/v2-0207819426ae2b06b83034030299336c_720w.jpg)

但是即使这样，在特定的采样点我们仍会得到错误的结果，如图中红色圆圈的红点，理论上它应该需要为其对应着色点计算贡献，但却由于深度测试 该点被错误判定为不可见，而导致结果产生多余的阴影

![img](https://pic4.zhimg.com/80/v2-5d1ae7d7d2973643a65262d0f28d1ad7_720w.jpg)

对于这样的错误，首先它并不会对最终结果造成太大的影响，其次SSAO也没有什么可靠的解决方案，所以在实际计算过程中我们一般选择忽略不计......

### HBAO

HBAO（Horizon-Based Ambient Occlusion）相比SSAO，不仅改善了冗余阴影的问题，还大大减少了采样率的需求，使得它成为了目前手机端最主流的环境光遮蔽算法

其主要思想是，使用**多次光线步进**找到**着色点切平面**与**遮挡物采样点**形成的最大角度，再通过这个角度来计算物体与物体间的遮挡程度，从而完成对环境光遮蔽的近似

![img](https://pic2.zhimg.com/80/v2-0711374f2abfd464775b35efc6f2d031_720w.jpg)

下图展示了SSAO与HBAO各自的效果，可以看到，二者还是存在一定质量上的差距的

![动图封面](https://pic2.zhimg.com/v2-3d3e18793efcd7e0518ab9362d29aaf5_b.jpg)

### SSDO

和HBAO一样，SSDO （Screen Space Directional Occlusion）也是一种对于SSAO的改进算法，它几乎照搬了pace tracing 、RSM的实现思路，通过在屏幕空间计算一系列次级光源对于shadingpoint的间接光照的贡献，与SSAO不同的是SSAO认为间接光照是处处恒定的，但SSDO认为在屏幕空间上直接被照亮的像素他们本身会成为提供间接光照的次级光源，以较小的代价取得了相比SSAO更为准确的结果

![](F:\计算机图形学\games202\35.png)

**实现原理**

其计算过程大致可以分为两部分——直接光照与间接光照：

- **直接光照**

下左图中，在着色点的法向半球内随机寻找若干采样点，为判断从shadingpoint点看向场景中其他位置的可见性，是通过从camera看向场景中的A,B,C,D点，根据之前记录的深度判断其可见性，以此确定是否要为该采样点计算直接光照。

下左图中， ![[公式]](https://www.zhihu.com/equation?tex=A%E3%80%81B%E3%80%81D) 均为遮挡，因此仅需要计算 ![[公式]](https://www.zhihu.com/equation?tex=C) 点的直接光照：

![img](https://pic2.zhimg.com/80/v2-39307089c3a730c2e65570b33fc464fd_720w.jpg)

- **间接光照**

在完成直接光照计算后，找到所有采样点在着色点法向半球内对应的表面微元，将它们设置为diffuse的次级光源，再依据次级光源的法线信息判断其有效性，对所有满足条件的次级光源计算间接光贡献（计算间接光照的方法和pacetracing是一样的）

下右图中， ![[公式]](https://www.zhihu.com/equation?tex=C) 点在法向半球以外， ![[公式]](https://www.zhihu.com/equation?tex=A) 点因法线朝向问题被判定为无效，所以最后只需计算 ![[公式]](https://www.zhihu.com/equation?tex=B) 点和 ![[公式]](https://www.zhihu.com/equation?tex=D) 点的间接光照即可

![img](https://pic1.zhimg.com/80/v2-166196465e29e60630dc68eaad5f0994_720w.jpg)

*（公式解释：* ![[公式]](https://www.zhihu.com/equation?tex=d_i) *为着色点* ![[公式]](https://www.zhihu.com/equation?tex=P) *到次级光源* ![[公式]](https://www.zhihu.com/equation?tex=P_i) *的距离，* ![[公式]](https://www.zhihu.com/equation?tex=%5Ccos%7B%5Ctheta_%7Bs_i%7D%7D) *为次级光源* ![[公式]](https://www.zhihu.com/equation?tex=P_i) *的法线与* ![[公式]](https://www.zhihu.com/equation?tex=%5Coverrightarrow%7BP_iP%7D) *的夹角余弦，* ![[公式]](https://www.zhihu.com/equation?tex=%5Ccos%7B%5Ctheta_%7Br_i%7D%7D) *为* ![[公式]](https://www.zhihu.com/equation?tex=P) *点法线与* ![[公式]](https://www.zhihu.com/equation?tex=%5Coverrightarrow%7BPP_i%7D) *的夹角余弦，* ![[公式]](https://www.zhihu.com/equation?tex=A_s) *为为调节渗光程度的因子，表示虚拟点光源的面积，此处为*![[公式]](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpi+r%5E2_%7Bmax%7D%7D%7BN%7D) *）*

![img](https://pic4.zhimg.com/80/v2-038aa3ffcf3db4634ed06b3d3489647f_720w.jpg)

可以看到，SSDO与SSAO的最大区别在于它们**计算间接光照的来源不同**，SSAO认为间接光来源于远处的未被遮挡的光线，而SSDO则认为它们来自于周围较近的遮挡物体的反射，正因为这一点，SSDO可以直接通过屏幕空间的像素颜色对间接光照进行估计，而不再需要将间接光照设为一个定值代入计算，也正因如此，SSDO的结果会得到更多的细节表现（color bleeding）

**SSDO存在的问题**

由于SSDO和SSAO一样是屏幕空间的计算方法，所以它具有一切使用屏幕空间算法的弊端，如错误遮挡，信息丢失等

![img](https://pic4.zhimg.com/80/v2-58b178339724a2be8eef741613911967_720w.jpg)



就以图中的A点和B点为例，对于A点，理论上应该分别对直接光照和间接光照进行计算，但是SSDO将其判定为不可见，并错误的设置了虚拟光源，导致在A点处产生了flase occlusion；而对于B点，在计算其直接光照时，SSDO直接计算了PB连线上的光照信息而忽略了遮挡，导致B点发生漏光

更重要的是，SSDO对间接光的近似方法是通过计算附近遮挡物的反射，所以它无法做到像SSAO那样考虑来自远处的间接光（其实按道理讲SSAO与SSDO应该互相配合着一起使用，但现实如何我们无从得知）

另外，屏幕空间的信息丢失对SSDO的影响也会更加明显，我们相当于从camera看向场景，场景作为一个“壳”，我们通过计算深度的方式记录的是最近的深度，但对于我们之间能看到这个“壳”背后的信息会发生丢失。因为几何特征的丢失会伴随着颜色信息的丢失，如下图中的两个长方体，随着它们摆放角度的逐渐垂直，地面上的颜色信息也会逐渐消失

![img](https://pic3.zhimg.com/80/v2-571017cc74dc8940989da7c8051aa0f2_720w.jpg)

### SSR

我们前面介绍的这三种方法，SSAO、HBAO与SSDO，都是基于屏幕空间的环境光遮蔽提出的GI近似算法，但它们对于间接光照的理解都没有触及到问题的本质。回顾一下我们一开始对于全局光照的定义，它的核心是如何通过模拟光线的**传播路径**来计算比直接光照**多一次bounce**的光照结果，也就是说，如果想要在屏幕空间得到一个更加真实的结果，还是得靠光线追踪才能实现。

托 延迟渲染 的福，现在的屏幕空间已经基本具备了所有模拟光线弹射的条件（法线，深度，balabala），那么剩下的问题就是如何与物体求交做shading，也就是我们接下来要介绍的最后一种方法——SSR（屏幕空间反射，screen-space relfections）

![](F:\计算机图形学\games202\37.png)

<img src="F:\计算机图形学\games202\38.png" style="zoom:50%;" />

<img src="F:\计算机图形学\games202\39.png" style="zoom: 50%;" />

**再提Ray-Marching**

因为在屏幕空间中只能获得场景几何最浅深度上的一些信息，所以我们无法再继续像3d空间那样用Möller-Trumbore等算法做Ray-casting了，那么为了计算光线与物体求交就必须转变一下思路，使用Ray-Marching来做判断

有关光线步进这个概念，我们已经在HBAO和之前的DFSS算法中多次提及，它无非就是让光线按一定步长向前迈进，同时判断是否与物体产生相交。

由于这种计算方式适用于无法通过套公式进行求交的情况，所以在体渲染中得到了大量的应用，而对于SSR屏幕空间，只要再在此基础上多加一步空间转换，配合DDA画线算法，就可以完成这步操作了

![img](https://pic1.zhimg.com/80/v2-bd4d516f1e6dea122b03b5f548a04928_720w.jpg)

**Hierarchical tracing加速结构**

现在我们解决了屏幕空间的求交问题，但显然这种方法对实时渲染来说太慢了，虽然这种逐像素逐步长Ray-Marching非常稳妥，但中间的过程存在大量的性能浪费，（如果步长过大判断相交会变得不准确，步长过小中间过程会产生性能浪费），这并不是我们所想看到的。那么有没有一种方法，既可以替代这种遍历式步进，又可以做到像三维的BVH / KD-Tree那样的加速效果呢？

于是有人就参照SDF，提出了一种基于动态步长的层级加速结构，这个结构有点类似Mipmap，会首先对深度缓存中的屏幕深度生成一个层级纹理，如果光线不能与第一层的块相交，那么更不可能与第零层的块（更粗糙的一层）相交，这个过程并不是像Mipmap那种做双线性插值，而是取四个像素的最小深度直接写入缓冲，如图

![img](https://pic3.zhimg.com/80/v2-0bd491cb0f94c5904051279c3373a14e_720w.jpg)

这时候我们再看下图的二维几何近似，可以发现这种层级结构刚好相当于对原场景生成了多个层级的包围盒，并且在级与级之间很自然的形成了一棵树形结构

![img](https://pic3.zhimg.com/80/v2-f86dda248ac64bb0184bf2007d6c91e2_720w.jpg)

直接上伪代码：

```c
void intersect(int level)
{
    while(level>-1)
    {
        for(i=0; i<4; i++)
        {
            if( hit level->node[i++] )
                level--;
                break;
        }
    }
}

int level = 0;
while(level>-1 && in screen)    //求交成功/失败->退出循环
{
    step through current cell;  //按当前level步长向前迈进
    if(above Z plane)
        level++;                //若没有交点，则加大步长
                  //增加一级的步长就等于在上一层更粗糙的层上移动一个步长的长度
    if(below Z plane) 
    {
        level--;                //若有交点则遍历当前层级
        intersect(level);       //定位到相交的子节点，随后缩短步长，在子节点层级继续求交
    }
}
```

![动图封面](https://pic3.zhimg.com/v2-ffead0a4018bc34efd2152d1a3a0bef6_b.jpg)



按paper的写法确实应该多一步增大步长，但这样会破坏树形结构，不太方便理解

![img](https://pic2.zhimg.com/80/v2-cf95e0171ec2eed570ed295407530d3d_720w.jpg)

**着色&采样方法**

求到光线与物体的交点，剩下的工作就简单了。SSR计算着色的方法几乎与路径追踪一模一样，如果是specular材质则cast一次，是glossy材质就用蒙特卡洛重要性采样多次计算（这里需要假设**次级反射物为diffuse**），正因为这一点，SSR才具备了实现许多路径追踪自带高质量效果的能力，如下图中的接触锐化和各向同性拉伸：

唯一的不同在于，SSR不用考虑光线的平方衰减，并且可以保证交点的可见性，这是因为SSR的**采样对象是brdf本身**，而只有在对光源采样的时候才要考虑衰减和遮挡...

至于对采样算法的优化，一方面我们可以采用之前的pre-filtering，通过提前对glossy反射波瓣的覆盖区域做滤波处理，来加快实际渲染速度。但这里有一点需要注意，屏幕空间的滤波操作还需要考虑深度值大小，但是深度值无法简单进行filter（原因如下图所示），在此我们不做深入讨论

![img](https://pic2.zhimg.com/80/v2-120819d7e4ae1b7b21e6ae158b85e829_720w.jpg)

另外，因为反射平面上邻近的两个着色点很有可能会采样到同一个交点，所以我们还可以对交点进行复用，如图：

![img](https://pic3.zhimg.com/80/v2-2eb91f225c889d3cc9c14d9536fa0862_720w.jpg)

**总结**

综合来看，SSR是一个极其优秀的屏幕空间算法，既能在实时的条件下根据不同材质得到不同的高质量结果，又能忽略前面AO算法中的各种遮挡问题，集各种优良性质于一身，属实nb

不过金无足赤，SSR也有自己不完美的地方，首先还是信息丢失的问题，这是屏幕空间算法的通病，无需多言

无需多言

![img](https://pic1.zhimg.com/80/v2-b94728fa83f9229971a63fd75500d6ec_720w.jpg)

另外还有就是它的硬边问题了，如果不做软化处理，结果会显得非常不自然，如图：

![img](https://pic3.zhimg.com/80/v2-180b1a205299b0312398b967e4d54966_720w.jpg)

## 基于物理的实时渲染

![img](https://pic3.zhimg.com/80/v2-b19d35199399930069a94c9d8db7cca2_720w.jpg)

> 基于物理的渲染（Physically Based Rendering，PBR）是指使用基于物理原理和微平面理论建模的着色/光照模型，以及使用从现实中测量的表面参数来准确表示真实世界材质的渲染理念

### **微表面模型**

在一般的渲染过程中，我们通常会忽略物体表面的微观几何形态，而直接以宏观平滑的假设对其进行渲染，然而事实上，这些微观的表面的确会对渲染结果造成一定的影响，如果不考虑它们，我们就永远无法精确的表示出BRDF。微表面模型（Microfacet model）就是这样一个**从宏观角度对微观进行建模**的一个理论，通过描述物体表面的微观法线的随机分布，从而达到表现更多材质细节的目的

在不考虑透明材质散射的情况下，我们可以由这些物理现象推导出一个一般情况下的BRDF表达式

![img](https://pic3.zhimg.com/80/v2-cbc89a93f3c87f489879b3e267b6f026_720w.jpg)

这就是著名的 *Microfacet Cook-Torrance BRDF*，它是目前应用最广、实现过程最为简单的微表面模型。其中，F是菲涅尔方程，D是法线分布函数，G是几何修正项，分母 4(n·i)(n·o) 是宏观与微观之间转换的校正因子，接下来会对这几项做详细的说明。  

**法线分布项：**微表面得法线分布与半程向量法线分布一致的情况下，才能将入射光线从 wi 反射到 wo 。D（h）表示微表面得法线分布对应在半程向量方向下函数的值是多少

**菲涅尔项：**表示了有多少百分率的能量会被反射

<img src="F:\计算机图形学\games202\40.png" style="zoom: 50%;" />

菲涅尔项在物理上考虑到 **S极化** 与 **P极化**，两种极化与介质的折射率、入射角、折射角相关，将两种极化加在一起除以2.

菲涅尔项可利用**Schlick近似**：

<img src="F:\计算机图形学\games202\41.png" style="zoom:50%;" />

R0为基础反射率（0度入射时的菲涅尔反射率）,与不同的物质的折射率有关。西特代表观察方向与法线的夹角。

以看到，当 θ=0° 时， R(θ)=0 ，而当 θ=90° ， R(θ)=1 ，整个函数呈现出单调增的形态，完美符合菲涅尔项的数据特征，且计算成本也相对低廉了许多

### **法线分布函数（NDF）**

法线分布函数 （Normal Distribution Function）描述了微观表面的法线概率分布，是微表面理论的核心。不同于其他光照模型的是，它更倾向于从微观的角度解释高光，即认为微表面法线越集中的物体 越容易表现出specular的性质，反之则越diffuse。



（另一种理解方式是，diffuse的微表面相当于是在glossy的表面高度场上做了一次缩放，加深了微表面之间的沟壑，打乱了原有的法线排布，从而使得物体看起来比原来更粗糙）

![img](https://pic4.zhimg.com/80/v2-75d9ea20d8a9ab26dac1b0059ad86b73_720w.jpg)

目前较为主流的（各向同性的）法线分布函数有Beckmann、GGX和GTR

#### **Beckmann**

Beckmann是一种定义在坡度空间上的类高斯分布模型，其表达式如下

![img](https://pic2.zhimg.com/80/v2-fd4b103c9b0cc90fe0e3ad990299d5a1_720w.jpg)

由于微表面的法线很难像宏观的法线那样直接写出来，所以我们通常使用微观半程向量 h 的一个函数代为表示，其中 α 是粗糙度系数（反应了微表面是glossy还是diffuse）， θh 是半程向量与宏观法线的夹角。而之所以要在坡度空间上使用 tan2⁡θh 来定义这个分布函数，是因为要满足高斯分布的定义域无限大的性质（球面上tanθ所处的空间是无限大的），保证函数无论何时都具有对应的非负值（tanθ在上平面上数值永远为正），并且避免微表面出现法线朝下的问题（但无法避免反射光朝下）

![img](https://pic1.zhimg.com/80/v2-d0defa4bfe5553148d5351287fb528d8_720w.jpg)

*（三维的情况对应的是切平面）*

#### **GGX / TR**

![img](https://pic3.zhimg.com/80/v2-18f31ed7adb4a4307c2d4c9f81235946_720w.jpg)

GGX相对于Beckmann在工业界得到了更为广泛的应用，因为它具有更好的高光拖尾（Long tail 性质，衰减更加柔和）

![img](https://pic2.zhimg.com/80/v2-4f2f0b9f939b4258151ffc424567477d_720w.jpg)

从下图可以看到，在相同粗糙度的情况下，GGX模型能表现出更好的光晕感，高光边缘也更加自然

![img](https://pic4.zhimg.com/80/v2-b87e9c6087498cf8ec3ebc232906bb27_720w.jpg)

#### **GTR**

GTR（Generalized TR）模型是对GGX模型的扩展，它在GGX的基础上新增了一个 γ 参数，用来调节高光拖尾的长度。当 γ=2 时，该模型与GGX互相等价

![img](https://pic1.zhimg.com/80/v2-76e7e6499e74d0366c771390cbbde338_720w.jpg)

### **几何修正项（Geometry）**

> 几何函数（Geometry Function）是一个0到1之间的标量，描述了微平面自阴影的属性，表示了具有半矢量法线的微平面中，同时被入射方向和反射方向可见（没有被遮挡的）的比例，即未被遮挡的 m=h 微表面的**百分比**

我们回到一开始说的Cook-Torrance BRDF模型，假设此时还尚未考虑任何几何修正的问题

![img](https://pic4.zhimg.com/80/v2-5e40c918a1c28d836eba91fc78abfd5f_720w.jpg)

那么如果这时候当我们以一个掠射角度观察物体，分母的校正因子就会变得非常小，而由于分子的菲涅尔项在grazing angle下具有接近100%的能量反射，整个式子在最后就会得到一个非常大的值，从而导致物体周围产生一圈异常的高光描边，这显然是非常不合理的。在现实中，由于微表面的互相遮挡，一部分光线会在物体表面发生损耗而无法直接抵达摄影机，这种损耗在掠射情况下会变得尤为明显，因此为了表现这种自遮挡，引入几何修正项就显得非常必要了

![img](https://pic4.zhimg.com/80/v2-89d11f332fda33506fa87ed582972793_720w.jpg)

具体在公式中，几何修正项的作用主要体现在两方面（如图），一种是**入射光在物体表面产生的自阴影**（Shadowing），另一种是**微表面对出射光的遮挡**（Masking），而由于光路的可逆性，我们可以认为两种情况的几何遮蔽效果是近似等效的，因此可以对它们使用相同的几何函数，即：

![img](https://pic3.zhimg.com/80/v2-b998ad6d18e1c8c5879ab86c168aa1ca_720w.jpg)

![img](https://pic4.zhimg.com/80/v2-0c6ac5923f85e9dda85989c90707c6e7_720w.jpg)

两种NDF在使用shadowing-masking项时的曲线的情况：

<img src="F:\计算机图形学\games202\42.png" style="zoom: 50%;" />

当观察方向与法线方向呈掠射 grazing angle时发生了急剧的遮挡。

### **能量补偿项**

在正确的引入几何项后，我们就基本可以解决边缘高光的问题了，不过这样又会引入一个新的问题——能量丢失。从图中可以看到，虽然实验的小球没有出现任何grazing angle的问题，但随着粗糙度的增加，其整体的色彩却发生了一定程度上的变暗；倘若我们对该小球的材质进行一次 *白炉测试* （即在假设 F(i,h)≡1 的情况下，使用 uniform irradiance=1 的天光，检测材质反射的能量是否为 1），这种现象会更加的明显

![img](https://pic3.zhimg.com/80/v2-b98895c753adebc418b480ef1125719e_720w.jpg)

产生这种现象的原因是我们在考虑几何修正项的时候，并没有把微表面之间的相互反射考虑进去，所以对于那些在微观几何表面发生了遮挡的光线，它们的能量就直接被cut掉了

为了解决这个问题，我们当然可以尝试去计算多重散射的微平面BRDF，去做一个类似光线追踪的递归运算，但对于实时渲染来说，这显然不是一个可行的解决方案

对此，工业界常用的处理方法是对原先的模型添加一个能量补偿项，通过**创建一个额外的BRDF波瓣**来近似估计丢失的能量。

**he Kulla-Conty Approximation**

首先我们还是假设 uniform irradiance=1（渲染方程中L=1），则微表面在经过一次bounce后出射的能量百分比可以表示为：

![img](https://pic2.zhimg.com/80/v2-9ad1cf9b757ce24792b47d39284a3a71_720w.jpg)

那么光线丢失的能量所占百分比就是 1−E(μo) ，推导过程如下：

（*相当于在求一个brdf的余弦加权半球积分，由于假设材质各向同性，* ω *可以直接用仰角* μ *替代）*

![img](https://pic3.zhimg.com/80/v2-5d0b364274285810b0bd47ed96b66ce6_720w.jpg)

那么我们用来能量补偿的BRDF就必须满足：

①光照方向的对称性，即交换 μo 和 μi 不改变BRDF的值；

②余弦加权半球积分值等于缺失能量百分比，即； Ems(μo)=1−E(μo) ；

根据第一个条件，可以先待定系数 c 写出 fms 的表达式：

![img](https://pic4.zhimg.com/80/v2-91a61ad6cb2c53440f3dbb93a143d1cf_720w.jpg)

再将其代入计算半球积分

![img](https://pic3.zhimg.com/80/v2-4dca6be5dc9999955a19bfded767caea_720w.jpg)

最后联立②，化简得

![img](https://pic1.zhimg.com/80/v2-71dbcf948ca8d7d123cfb5b063ed6ab4_720w.jpg)

其中 Eavg 是半球上E的余弦加权平均值，取值仅依赖于粗糙度 α ，**可以用一维纹理或者曲线进行储存**

![img](https://pic4.zhimg.com/80/v2-ed3bcc725a6991210a5d803aeed5b1eb_720w.jpg)

<img src="F:\计算机图形学\games202\43.png" style="zoom:50%;" />

E(μo) 和 E(μi) 则同时依赖粗糙度α 和仰角 μ ，**需要利用一张2D纹理经过预计算才能完成储存**，不过由于它们的函数变化相对较为平缓，所以一般选用32×32分辨率就可以满足需求了

![img](https://pic1.zhimg.com/80/v2-2a10ac9a45bb13e0f222959e3796236c_720w.jpg)

如果该Microfacet BRDF还带有颜色信息，则可以认为其表面本身就具备吸收（或放出）能量的性质，其额外的BRDF项为：

​                                                                        **颜色项：**

![img](https://pic4.zhimg.com/80/v2-86bb7e410cec7d5cad1cb266add4736f_720w.jpg)

其中 ， Favg 为平均菲涅尔项（**宏观的菲涅尔效应是微观菲涅尔的均值**，所以还是半球上的余弦加权平均，在半球面不同角度下，对于菲涅尔项的平均）：

<img src="F:\计算机图形学\games202\45.png" style="zoom:50%;" />

（任何一个项在某种积分域上的积分，再除以空积分，就会得到平均值）

<img src="F:\计算机图形学\games202\46.png" style="zoom:50%;" />

​	**Eavg**： 给定一个反射的方向，出射的能量（不会参与到多次的bounce的能量）是多少

<img src="F:\计算机图形学\games202\44.png" style="zoom: 67%;" />

最后，考虑了能量补偿的渲染方程将如下所示：

![img](https://pic2.zhimg.com/80/v2-6688d41d0131200cf18f40e0748037d9_720w.jpg)

带有能量信息的颜色补偿结果：

![img](https://pic3.zhimg.com/80/v2-d52402af3e66d2142abc6cb871bf792e_720w.jpg)

### **线性变换余弦（LTC）**

LTC（Linearly Transformed Cosines）是一种专门为了解决微表面模型下 **多边形光源采样问题** 的一种（无阴影）着色方法，它通过将标准空间中的反射波瓣线性映射到余弦空间，完成了对原BRDF分布的拟合，从而大大的提升了面光源积分的计算效率，是一个非常厉害的算法（目前主要用于GGX模型下的PBR渲染，但对其他模型也同样适用）

对于任意的 brdf 对于任意的多边形光源的shadingpoint进行ji分的问题，转化为在固定的余弦下对于任意的多边形光源进行积分，这个积分是有解析解的。

![img](https://pic2.zhimg.com/80/v2-809863024fb4509911b2464284baa76d_720w.jpg)

该方法的核心可以简单概括为三步：

- 首先假设面光源的L_i是uniform的，求出标准空间内的BRDF表达式，并储存在一张二维纹理中

![img](https://pic3.zhimg.com/80/v2-ae64807c4da1e8d047fcc3b81f64c462_720w.jpg)

- 对任意观察方向预计算一个变化矩阵 M ，将标准空间的BRDF转化到余弦空间（原paper是将余弦空间转化为标准空间，所以图中是乘以 M−1 ）

![img](https://pic3.zhimg.com/80/v2-41e4e58a239a8829e08415ed2d51f37e_720w.jpg)

![img](https://pic4.zhimg.com/80/v2-2a69faf1643b83884900068a0acbbe43_720w.jpg)

由于该变换过程作用于所有输入的输入 ωi ，所以也就等价于将整个面光源（积分域）也进行了线性变换

![img](https://pic3.zhimg.com/80/v2-399a526ed0eaa1b7fb45a1e3d6d16cba_720w.jpg)

- 求出与 M 相对应的雅克比项，保存为一张纹理，以此避免在后续空间转换中面光源的面积发生变化

![img](https://pic3.zhimg.com/80/v2-c64053c91c76d68885489ac6c46cda16_720w.jpg)

## **迪士尼原则的BRDF**

在2012年迪士尼原则的BRDF被正式提出之前，PBR并未在工业界得到广泛的关注，就算Microfacet模型在很多情况下可以做到非常接近真实的物理材质，它仍旧存在着如下的两个问题：

1° 易用性。微表面的整套理论体系充斥着大量的复杂而不直观的参数，还有诸如金属反射率的复数域计算等的复杂数学概念，这些对于艺术家们的调参工作是极其不友好的

2° 复合材质的局限性。现实中的材质常常不会单独出现，比如家装使用的清漆，还有玻璃上的塑料薄膜，这些都或多或少对diffuse和specular材质进行了一定组合，而微表面模型是无法解释这种多层材质的渲染的，因此具有一定的局限性

于是，迪士尼动画工作室就开发出了一种**艺术导向**的着色模型，大大改善了传统的PBR的工业流程，其核心理念如下

1. 应使用直观的参数，而不是物理类的晦涩参数
2. 参数应尽可能少
3. 调参范围应尽量保持在0到1范围内，最好有拖动条配合进行控制
4. 允许参数在必要的情况下超出正常的合理范围
5. 所有参数组合应尽可能可靠合理

以 上述五条理念为基础，最后得到了一个颜色参数（baseColor）和十个标量参数

![img](https://pic4.zhimg.com/80/v2-79d724a712c478a703b5a02e96f5b14f_720w.jpg)

- **baseColor（基础色）**：表面颜色，通常由纹理贴图提供
- **subsurface（次表面）**：是一种比diffuse还要平的效果，可以用来近似的控制漫反射形状
- **metallic（金属度）**：0表示电介质，1表示金属，是两种不同模型之间的线性混合。其中金属模型没有漫反射成分，并且还具有等于基础色的着色入射镜面反射
- **specular（镜面反射强度）**：0表示电介质，1表示金属，控制材质镜面反射的反射量，可以用来取代折射率
- **specularTint（镜面反射颜色）**：属于对美术控制的让步，用来控制镜面反射的颜色，0表示无色，1表示材质固有色，但掠射镜面反射不论何时都为无色
- **roughness（粗糙度）**：0表示镜面反射，1表示漫反射
- **anisotropic（各向异性强度）**：0表示最大各向同性，1表示最大各向异性
- **sheen（光泽度）**：一种额外的掠射分量，控制物体的绒毛质感，主要用于布料
- **sheenTint（光泽颜色）**：控制sheen的颜色，0表示无色，1表示材质固有色
- **clearcoat（清漆强度）**：第二个镜面波瓣，控制透明涂层的明显程度
- **clearcoatGloss（清漆光泽度）**：控制透明涂层的光泽度，0表示磨砂，1表示光滑

以上所有属性均可以混合使用

| Pros                                          | Cons                               |
| --------------------------------------------- | ---------------------------------- |
| 易于使用，方便理解，支持参数混叠， 且完全开源 | 巨大的参数空间，可能会造成参数冗余 |

| Q：Disney模型是不是无所谓能量守恒？                          |
| ------------------------------------------------------------ |
| A：是的，这个模型拟合的就是能量守恒的模型，如果不考虑拟合误差，那么它本身就是能量守恒的 |
| Q：游戏引擎里用Disney吗？                                    |
| A：不用，Disney不太适合实时渲染，如果用Disney，那么整个一套算法都得改 |
| Q：Microfacet有没有能力表示diffuse表面？                     |
| A：考虑能量补偿的情况下，只要材质粗糙度足够高就可以表示      |